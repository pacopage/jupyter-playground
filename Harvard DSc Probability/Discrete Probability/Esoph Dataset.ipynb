{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esoph Dataset, see https://galeascience.wordpress.com/2016/05/05/linear-models-for-predicting-esophagus-cancer-likelihood/\n",
    "\n",
    "Step 1: get it into torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas\n",
    "\n",
    "esoph = sm.datasets.get_rdataset('esoph')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = esoph.data\n",
    "gdef_1 = df.columns[0]\n",
    "gdef_2 = df.columns[1]\n",
    "gdef_3 = df.columns[2]\n",
    "\n",
    "gdef_1_vals = df[gdef_1].unique()\n",
    "gdef_2_vals = df[gdef_2].unique()\n",
    "gdef_3_vals = df[gdef_3].unique()\n",
    "\n",
    "gdef_1_dict = { gdef_1_vals[i] : i for i in range(0, len(gdef_1_vals) ) }\n",
    "gdef_2_dict = { gdef_2_vals[i] : i for i in range(0, len(gdef_2_vals) ) }\n",
    "gdef_3_dict = { gdef_3_vals[i] : i for i in range(0, len(gdef_3_vals) ) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agegp</th>\n",
       "      <th>alcgp</th>\n",
       "      <th>tobgp</th>\n",
       "      <th>ncases</th>\n",
       "      <th>ncontrols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agegp  alcgp  tobgp  ncases  ncontrols\n",
       "0      0      0      0       0         40\n",
       "1      0      0      1       0         10\n",
       "2      0      0      2       0          6\n",
       "3      0      0      3       0          5\n",
       "4      0      1      0       0         27"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df = df.replace({ gdef_1 : gdef_1_dict, gdef_2 : gdef_2_dict, gdef_3 : gdef_3_dict})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "t = torch.from_numpy(cleaned_df.to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    }
   ],
   "source": [
    "groups = t.size()[0]\n",
    "print(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "cases = torch.sum(t[:,3]).item()\n",
    "print(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975\n"
     ]
    }
   ],
   "source": [
    "controls = torch.sum(t[:,4]).item()\n",
    "print(controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4017857142857143\n",
      "0.06531531531531531\n"
     ]
    }
   ],
   "source": [
    "highest_alc_gr = len(gdef_2_vals) - 1\n",
    "lowest_alc_gr = 0\n",
    "\n",
    "acl_gr = t[:,1]\n",
    "highest_acl_rows = torch.index_select(t, 0, torch.where(acl_gr == highest_alc_gr, torch.ones(1), torch.zeros(1)).nonzero()[:,0])\n",
    "lowest_acl_rows = torch.index_select(t, 0, torch.where(acl_gr == lowest_alc_gr, torch.ones(1), torch.zeros(1)).nonzero()[:,0])\n",
    "\n",
    "highest_alc_cancer_count = torch.sum(highest_acl_rows[:,3]).item()\n",
    "highest_alc_control_count = torch.sum(highest_acl_rows[:,4]).item()\n",
    "lowest_alc_cancer_count = torch.sum(lowest_acl_rows[:,3]).item()\n",
    "lowest_alc_control_count = torch.sum(lowest_acl_rows[:,4]).item()\n",
    "\n",
    "highest_alc_cancer_prob = highest_alc_cancer_count / (highest_alc_cancer_count + highest_alc_control_count)\n",
    "lowest_alc_cancer_prob = lowest_alc_cancer_count / (lowest_alc_cancer_count + lowest_alc_control_count)\n",
    "\n",
    "print(highest_alc_cancer_prob)\n",
    "print(lowest_alc_cancer_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61\n",
      "0.46153846153846156\n"
     ]
    }
   ],
   "source": [
    "at_least_10g_tob = 1\n",
    "case_col = t[:,3]\n",
    "control_col = t[:,4]\n",
    "\n",
    "has_case = case_col > 0\n",
    "has_control = control_col > 0\n",
    "has_at_least10g = t[:,2] > 0\n",
    "\n",
    "all_cases_rows_10g_tob_least = torch.index_select(t, 0, torch.where(has_case & has_at_least10g, torch.ones(1), torch.zeros(1)).nonzero()[:,0]) \n",
    "all_control_rows_10g_tob_least = torch.index_select(t, 0, torch.where(has_control & has_at_least10g, torch.ones(1), torch.zeros(1)).nonzero()[:,0]) \n",
    "\n",
    "prob_10g_cases = torch.sum(all_cases_rows_10g_tob_least[:,3]).item() / cases\n",
    "prob_10g_control = torch.sum(all_control_rows_10g_tob_least[:,4]).item() /controls\n",
    "\n",
    "print(prob_10g_cases)\n",
    "print(prob_10g_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.225\n"
     ]
    }
   ],
   "source": [
    "print(highest_alc_cancer_count / cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.155\n"
     ]
    }
   ],
   "source": [
    "highest_tob_gr = len(gdef_3_vals) - 1\n",
    "\n",
    "tob_gr = t[:,2]\n",
    "highest_tob_rows = torch.index_select(t, 0, torch.where(tob_gr == highest_tob_gr, torch.ones(1), torch.zeros(1)).nonzero()[:,0])\n",
    "\n",
    "highest_tob_cancer_count = torch.sum(highest_tob_rows[:,3]).item()\n",
    "print(highest_tob_cancer_count / cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n"
     ]
    }
   ],
   "source": [
    "high_tob = tob_gr == highest_tob_gr\n",
    "high_alc = acl_gr == highest_alc_gr\n",
    "\n",
    "highest_all_rows = torch.index_select(t, 0, torch.where(high_tob & high_alc, torch.ones(1), torch.zeros(1)).nonzero()[:,0])\n",
    "\n",
    "highest_all_cancer_count = torch.sum(highest_all_rows[:,3]).item()\n",
    "print(highest_all_cancer_count / cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33\n"
     ]
    }
   ],
   "source": [
    "highest_or_rows = torch.index_select(t, 0, torch.where(high_tob | high_alc, torch.ones(1), torch.zeros(1)).nonzero()[:,0])\n",
    "\n",
    "highest_or_cancer_count = torch.sum(highest_or_rows[:,3]).item()\n",
    "print(highest_or_cancer_count / cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06871794871794872\n"
     ]
    }
   ],
   "source": [
    "print(highest_alc_control_count / controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2742537313432836\n"
     ]
    }
   ],
   "source": [
    "print((highest_alc_cancer_count / cases) / (highest_alc_control_count / controls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0841025641025641\n"
     ]
    }
   ],
   "source": [
    "highest_tob_control_count = torch.sum(highest_tob_rows[:,4]).item()\n",
    "print(highest_tob_control_count / controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013333333333333334\n"
     ]
    }
   ],
   "source": [
    "highest_all_control_count = torch.sum(highest_all_rows[:,4]).item()\n",
    "print(highest_all_control_count / controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13948717948717948\n"
     ]
    }
   ],
   "source": [
    "highest_or_control_count = torch.sum(highest_or_rows[:,4]).item()\n",
    "print(highest_or_control_count / controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.365808823529412\n"
     ]
    }
   ],
   "source": [
    "print((highest_or_cancer_count / cases)/(highest_or_control_count / controls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
